# Privacy-Preserving Distributed Expectation Maximization for Gaussian Mixture Models  
*Prof. Adi Akavia's Secure Cloud Computing Laboratory, Fall 2022-2023*  
  
  

  
## Step-by-step guide to our repository:  
- Firstly, read the [background](Background.md) document. This document serves as our preliminaries and problem setup, where we introduce and explain the key concepts of Gaussian mixture models, the expectation maximization algorithm, and fully homomorphic encryption.  
- You can now check out the [colab notebooks](Notebooks) for the aweswome visuliaztion!  
  (Also available at [2D GMM Visualiztion](2D_GMM_Visualiztion)).  
- Secondly, read our [proposed approach](Proposed_Approach.md), where we explain our solution in detail and show the results.  





## Requirements:  
- numpy
- matplotlib
- scipy
- copy
- tenseal

  
## Citations  
```
@misc{tenseal2021,
    title={TenSEAL: A Library for Encrypted Tensor Operations Using Homomorphic Encryption}, 
    author={Ayoub Benaissa and Bilal Retiat and Bogdan Cebere and Alaa Eddine Belfedhal},
    year={2021},
    eprint={2104.03152},
    archivePrefix={arXiv},
    primaryClass={cs.CR}
}
```  
  
```
@misc{li2022privacy,
title={Privacy-Preserving Distributed Expectation Maximization For Gaussian Mixture Model Using Subspace Perturbation},
author={Li, Qiongxiu and Gundersen, Jaron S. and Tjell, Katrine and Wisniewski, Rafal and Christensen, Mads G.},
year={2022},
eprint={2202.11213},
archivePrefix={arXiv},
primaryClass={cs.CR}
}
```
